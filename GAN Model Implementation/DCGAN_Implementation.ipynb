{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title <p>Essential Import\n",
        "import os, shutil, json\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np, pandas as pd, random as rd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "5_7Hk79GxmqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p>Torch Essential Import\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "2cWi1vG7xna6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, image_ch, features_d):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        self._block(image_ch, features_d, 4, 2, 1),\n",
        "        self._block(features_d, features_d *2, 4, 2, 1),\n",
        "        self._block(features_d *2, features_d *4, 4, 2, 1),\n",
        "        self._block(features_d *4, features_d *8, 4, 2, 1),\n",
        "        nn.Conv2d(features_d * 8, 1, 4, 2, 0),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def _block(self, in_ch, out_ch, kernel_size, stride, padding):\n",
        "    block = nn.Sequential(\n",
        "        nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "    return block\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.disc(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_ch, image_ch, features_g):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        self._block(noise_ch, features_g * 16, 4, 1, 0),\n",
        "        self._block(features_g * 16, features_g * 8, 4, 2, 1),\n",
        "        self._block(features_g * 8, features_g *4, 4, 2, 1),\n",
        "        self._block(features_g * 4, features_g *2, 4, 2, 1),\n",
        "        nn.ConvTranspose2d(\n",
        "            features_g * 2, image_ch, 4, 2, 1\n",
        "        ),\n",
        "        # Output: N x image_ch x 64 x 64\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def _block(self, in_ch, out_ch, kernel_size, stride, padding):\n",
        "    block = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_ch, out_ch, kernel_size, stride, padding),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "    return block\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "XNWrJJHRxodH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "  for m in model.modules():\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "      nn.init.normal(m.weight.data, 0.0, 0.02)"
      ],
      "metadata": {
        "id": "v-0xWS9-TD6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  N, in_ch, H, W = 8, 3, 64, 64\n",
        "  noise_dim = 100\n",
        "  x = torch.randn((N, in_ch, H, W))\n",
        "  disc = Discriminator(in_ch, 8)\n",
        "  print(f\"Disc shape : {disc(x).shape}\")\n",
        "  assert disc(x).shape == (N, 1, 1, 1), \"Discriminator test failed\"\n",
        "  gen = Generator(noise_dim, in_ch, 8)\n",
        "  z = torch.randn((N, noise_dim, 1, 1))\n",
        "  print(f\"Gen shape : {gen(z).shape}\")\n",
        "  assert gen(z).shape == (N, in_ch, H, W), \"Generator test failed\"\n",
        "  print(\"Succes test passed!\")"
      ],
      "metadata": {
        "id": "i5gjLx_yTzyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKAmVCTvUkcJ",
        "outputId": "86833a46-3090-46c9-f942-a963e618864d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disc shape : torch.Size([8, 1, 1, 1])\n",
            "Gen shape : torch.Size([8, 3, 64, 64])\n",
            "Succes test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 5e-5\n",
        "BS = 64\n",
        "IMAGE_SIZE = 64\n",
        "IMAGE_CH = 1\n",
        "Z_DIM = 100\n",
        "NUM_EPOCHS = 5\n",
        "FEATURES_CRITIC = 64\n",
        "FEATURES_GEN = 64\n",
        "CRITIC_ITERATIONS = 5\n",
        "WEIGHT_CLIP = 1e-2\n",
        "\n",
        "transforms = T.Compose([\n",
        "    T.Resize(IMAGE_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(\n",
        "        [0.5 for _ in range(IMAGE_CH)],\n",
        "        [0.5 for _ in range (IMAGE_CH)]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "8J_0jiaVUqb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms, download=True)\n",
        "loader = DataLoader(dataset, batch_size = BS, shuffle=True)\n",
        "\n",
        "gen = Generator(Z_DIM, IMAGE_CH, FEATURES_GEN).to(device)\n",
        "disc = Discriminator(IMAGE_CH, FEATURES_CRITIC).to(device)\n",
        "\n",
        "initialize_weights(gen)\n",
        "initialize_weights(disc)\n",
        "\n",
        "opt_gen = torch.optim.RMSprop(gen.parameters(), lr = LR)\n",
        "opt_disc = torch.optim.RMSprop(disc.parameters(), lr = LR)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
        "writer_real = SummaryWriter(f\"logs/real\")\n",
        "writer_fake = SummaryWriter(f\"logs/fake\")\n",
        "step = 0\n",
        "\n",
        "gen.train()\n",
        "disc.train()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  # Target labels not needed! <3 unsupervised\n",
        "  for idx, (real, _) in enumerate(loader):\n",
        "    real = real.to(device)\n",
        "    noise = torch.randn(BS, Z_DIM, 1, 1).to(device)\n",
        "    fake = gen(noise)\n",
        "\n",
        "    ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
        "    disc_real = disc(real).to(device)\n",
        "    loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
        "    disc_fake = disc(fake.detach()).reshape(-1)\n",
        "    loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
        "    loss_disc = (loss_disc_real + loss_disc_fake)/2\n",
        "\n",
        "    disc.zero_grad()\n",
        "    loss_disc.backward()\n",
        "    opt_disc.step()\n",
        "\n",
        "    ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
        "    output = disc(fake).reshape(-1)\n",
        "    loss_gen = criterion(output, torch.ones_like(output))\n",
        "\n",
        "    gen.zero_grad()\n",
        "    loss_gen.backward()\n",
        "    opt_gen.step()\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print(\n",
        "          f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {idx}/{len(loader)} \\\n",
        "          Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\"\n",
        "      )\n",
        "\n",
        "    with torch.no_grad():\n",
        "      fake = gen(fixed_noise)\n",
        "\n",
        "      # take out (up to) 32 examples\n",
        "      img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
        "      img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
        "\n",
        "    step+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "oaaUPrsoWlja",
        "outputId": "4266aed2-2b7c-4931-fea4-1c8e2c79c804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/5] Batch 0/938           Loss D: 0.7028, Loss G: 0.6520\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-5938fc98808b>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mloss_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mloss_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mopt_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mef9gyAUg5F6",
        "outputId": "f6937b97-fcf8-4600-eaae-23edd7e1fa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.5232, 1.5237, 1.5237, 1.5240, 1.5244, 1.5243, 1.5240, 1.5237, 1.5242,\n",
              "        1.5238, 1.5240, 1.5241, 1.5242, 1.5240, 1.5238, 1.5240, 1.5237, 1.5241,\n",
              "        1.5237, 1.5238, 1.5240, 1.5239, 1.5243, 1.5241, 1.5241, 1.5239, 1.5243,\n",
              "        1.5244, 1.5232, 1.5240, 1.5241, 1.5246, 1.5241, 1.5237, 1.5241, 1.5241,\n",
              "        1.5238, 1.5236, 1.5239, 1.5238, 1.5247, 1.5236, 1.5239, 1.5239, 1.5238,\n",
              "        1.5240, 1.5244, 1.5241, 1.5236, 1.5241, 1.5236, 1.5236, 1.5242, 1.5243,\n",
              "        1.5245, 1.5239, 1.5239, 1.5239, 1.5243, 1.5237, 1.5239, 1.5240, 1.5246,\n",
              "        1.5238], grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7e2BFwqVhBL7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}